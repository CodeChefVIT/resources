# PySpark
<br>

PySpark is an interface for Apache Spark in Python. It not only allows you to write Spark applications using Python APIs, but also provides the PySpark shell for interactively analyzing your data in a distributed environment. PySpark supports most of Sparkâ€™s features such as Spark SQL, DataFrame, Streaming, MLlib (Machine Learning) and Spark Core.
## Complete  Courses

- For learning deep, you can go ahead with [this](https://www.udemy.com/course/pyspark-essentials-for-data-scientists-big-data-python/) and [this](https://www.udemy.com/course/spark-and-python-for-big-data-with-pyspark/) paid course on Udemy.

## Videos lectures

- [This lecture series has very good introduction to PySpark](https://www.youtube.com/watch?v=_C8kWso4ne4)

## Documentation

- Documentation can be found [here](http://spark.apache.org/docs/latest/api/python/)

# Diving Deep

- [PySpark tutorial](https://www.tutorialspoint.com/pyspark/index.htm)
- [Pyspark tutorial 2](https://www.javatpoint.com/pyspark)

